{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LAB2_P4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ2vogLD76rF",
        "colab_type": "code",
        "outputId": "28a112aa-e78a-463f-985c-377edaa112de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#importing all the libraries\n",
        "import pandas as pd \n",
        "#using pandas dataframe to read csv file\n",
        "#importing all libraries from keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Dropout, Conv1D, GlobalMaxPooling1D\n",
        "from matplotlib import pyplot\n",
        "#using sklearn for normalizing the data and splitting the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import re\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "#using the tensorboard to log the log files\n",
        "from keras.callbacks import TensorBoard\n",
        "from time import time\n",
        "tensorboard=TensorBoard(log_dir=\"log/{}\".format(time()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGU3PyCjBtnG",
        "colab_type": "code",
        "outputId": "d254264d-6c5c-4380-c787-cf054d2b2cc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "\n",
        "#reading the csv file \n",
        "tsrain_data= pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Pysthon_LAB2/Lab2_5_Data/train.tsv\", sep=\"\\t\")\n",
        "tsest_data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Pysthon_LAB2/Lab2_5_Data/test.tsv\", sep=\"\\t\")\n",
        "tsrain_data.head"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(156060, 4)\n",
            "(156060, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of         PhraseId  ...  Sentiment\n",
              "0              1  ...          1\n",
              "1              2  ...          2\n",
              "2              3  ...          2\n",
              "3              4  ...          2\n",
              "4              5  ...          2\n",
              "...          ...  ...        ...\n",
              "156055    156056  ...          2\n",
              "156056    156057  ...          1\n",
              "156057    156058  ...          3\n",
              "156058    156059  ...          2\n",
              "156059    156060  ...          2\n",
              "\n",
              "[156060 rows x 4 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3HkdLa1CRZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dropping out columns\n",
        "tsrain_data = train_data.drop(columns=['PhraseId', 'SentenceId'])\n",
        "tsest_data = test_data.drop(columns=['PhraseId', 'SentenceId'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byzKzyALlc_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#taking the target variable\n",
        "lsabel=train_data[['Sentiment']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-b3mhf2ld8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#droping the target column for training\n",
        "tsrain_data=tsrain_data.drop(columns=['Sentiment'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PXicwjrCR_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#converting all to lowercase\n",
        "tsrain_data['Phrase'] = tsrain_data['Phrase'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]', '', x.lower()))\n",
        "tsest_data['Phrase'] = tsest_data['Phrase'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]', '', x.lower()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQSUHASQCUGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#keeping max features as 5000\n",
        "max_fatures =5000\n",
        "#Tokenizing the sentence\n",
        "tsokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tsokenizer.fit_on_texts(tsrain_data['Phrase'].values)\n",
        "X_tsrain = tsokenizer.texts_to_sequences(tsrain_data['Phrase'].values)\n",
        "X_tsrain = pad_sequences(X_tsrain)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z56ME5mvCWZi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#keeping max features as 2000 for test for matching of shape\n",
        "max_fatures = 2000\n",
        "#tokenizing each sentence\n",
        "tsokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tsokenizer.fit_on_texts(tsest_data['Phrase'].values)\n",
        "X_tsest = tsokenizer.texts_to_sequences(tsest_data['Phrase'].values)\n",
        "X_tsest = pad_sequences(X_tsest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzbQllUtmA55",
        "colab_type": "code",
        "outputId": "e0648f84-8c92-4ed8-ce01-8da496a98f8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_tsrain.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156060, 46)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duyiCV2ZmEfO",
        "colab_type": "code",
        "outputId": "51a32738-7f1b-48c1-af0a-ee445fc0678a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_tsest.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(66292, 46)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GnY9RklCYJ-",
        "colab_type": "code",
        "outputId": "fed99e09-d969-4cab-c54f-555fa70469d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "#ONEHOT each target label\n",
        "abel_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(lsabel)\n",
        "Y_tsrain = to_categorical(integer_encoded)\n",
        "using train_test_split for splitting train and test data\n",
        "Xs_tr, Xs_te, Ys_tr, Ys_te = train_test_split(X_tsrain, Y_tsrain, test_size=0.25, random_state=30)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(117045, 46) (117045, 5)\n",
            "(39015, 46) (39015, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrkFOO3OCaNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#building the model we have used embedding layer, conv1d layer and maxpooling layer\n",
        "num_classesS = Y_tSrain.shape[1]\n",
        "msax_words= X_tSrain.shape[1]\n",
        "msodel= Sequential()\n",
        "msodel.add(Embedding(msax_features,100,input_length=msax_words))\n",
        "msodel.add(Dropout(0.2))\n",
        "msodel.add(Conv1D(64,kernel_size=3,padding='same',activation='relu',strides=1))\n",
        "msodel.add(GlobalMaxPooling1D())\n",
        "msodel.add(Dense(128,activation='relu'))\n",
        "msodel.add(Dropout(0.2))\n",
        "msodel.add(Dense(num_classess,activation='softmax'))\n",
        "msodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSVuqXpiER-0",
        "colab_type": "code",
        "outputId": "1deb6e06-3001-4e3b-8c38-9742f932d786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "his=model.fit(Xs_tr, Ys_tr, validation_data=(Xs_te, Ys_te),epochs=5, batch_size=512, verbose=1, callbacks=[tensorboard])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 117045 samples, validate on 39015 samples\n",
            "Epoch 1/5\n",
            "117045/117045 [==============================] - 31s 262us/step - loss: 1.1564 - accuracy: 0.5528 - val_loss: 0.9662 - val_accuracy: 0.6139\n",
            "Epoch 2/5\n",
            "117045/117045 [==============================] - 30s 257us/step - loss: 0.9186 - accuracy: 0.6363 - val_loss: 0.9177 - val_accuracy: 0.6310\n",
            "Epoch 3/5\n",
            "117045/117045 [==============================] - 30s 260us/step - loss: 0.8569 - accuracy: 0.6598 - val_loss: 0.8810 - val_accuracy: 0.6465\n",
            "Epoch 4/5\n",
            "117045/117045 [==============================] - 30s 255us/step - loss: 0.8118 - accuracy: 0.6761 - val_loss: 0.8740 - val_accuracy: 0.6493\n",
            "Epoch 5/5\n",
            "117045/117045 [==============================] - 30s 258us/step - loss: 0.7772 - accuracy: 0.6904 - val_loss: 0.8648 - val_accuracy: 0.6539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui01C_5jnZxN",
        "colab_type": "code",
        "outputId": "7093fa45-ab25-4de4-c447-138ac2d5af9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "msodel.predict_classes(Xs_te[:1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__UODK6Mniey",
        "colab_type": "code",
        "outputId": "7e256eae-6d2f-4aa2-ddb8-7541afb88beb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Ys_te[2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 1., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtLq8bgwno3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ys_pred=model.predict_classes(X_tsest[:1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JY6Ak7snvb0",
        "colab_type": "code",
        "outputId": "79a1cfac-44c3-4d94-8558-3a7bb02b0fd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "susb_file = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Pysthon_LAB2/Lab2_5_Data/sampleSubmission.csv',sep=',')\n",
        "susb_file.iloc[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PhraseId     156061\n",
              "Sentiment         2\n",
              "Name: 0, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcYqaqIYpQWI",
        "colab_type": "code",
        "outputId": "7ad0d7b0-44e1-4417-fbd6-107f52e82302",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(\"PREDICTED LABEL \",ys_pred[0])\n",
        "print(\"ACTUAL LABEL  \",susb_file['Sentiment'].iloc[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PREDICTED LABEL  2\n",
            "ACTUAL LABEL   2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLGgsJOVMcPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import adam\n",
        "ss=adam(lr=0.001)\n",
        "model1= Sequential()\n",
        "model1.add(Embedding(msax_features,100,input_length=msax_words))\n",
        "model1.add(Dropout(0.2))\n",
        "model1.add(Conv1D(64,kernel_size=3,padding='same',activation='relu',strides=1))\n",
        "model1.add(GlobalMaxPooling1D())\n",
        "model1.add(Dense(128,activation='relu'))\n",
        "model1.add(Dropout(0.2))\n",
        "model1.add(Dense(num_classes,activation='softmax'))\n",
        "model1.compile(loss='binary_crossentropy',optimizer=s,metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq0lX4HAM2Cs",
        "colab_type": "code",
        "outputId": "b1e7b8d8-119f-420b-94cd-40844fea1924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "his=msodel1.fit(Xs_tr, Ys_tr, validation_data=(Xs_te, Ys_te),epochs=5, batch_size=51, verbose=1, callbacks=[tsensorboard])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 117045 samples, validate on 39015 samples\n",
            "Epoch 1/5\n",
            "117045/117045 [==============================] - 45s 384us/step - loss: 0.3548 - accuracy: 0.8444 - val_loss: 0.3305 - val_accuracy: 0.8520\n",
            "Epoch 2/5\n",
            "117045/117045 [==============================] - 44s 377us/step - loss: 0.3237 - accuracy: 0.8564 - val_loss: 0.3247 - val_accuracy: 0.8547\n",
            "Epoch 3/5\n",
            "117045/117045 [==============================] - 45s 380us/step - loss: 0.3109 - accuracy: 0.8621 - val_loss: 0.3183 - val_accuracy: 0.8584\n",
            "Epoch 4/5\n",
            "117045/117045 [==============================] - 44s 375us/step - loss: 0.3022 - accuracy: 0.8664 - val_loss: 0.3175 - val_accuracy: 0.8582\n",
            "Epoch 5/5\n",
            "117045/117045 [==============================] - 44s 377us/step - loss: 0.2952 - accuracy: 0.8699 - val_loss: 0.3179 - val_accuracy: 0.8569\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}